{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/irisTraining.txt\", delim_whitespace=True, header=None)\n",
    "X_train = train.iloc[:, :-1].values  # Features\n",
    "y_train = train.iloc[:, -1].values    # Target\n",
    "# y_train[y_train == -1] = 0\n",
    "\n",
    "test = pd.read_csv(\"datasets/irisTesting.txt\", delim_whitespace=True, header=None)\n",
    "X_test = test.iloc[:, :-1].values  # Features\n",
    "y_test = test.iloc[:, -1].values    # Target\n",
    "# y_test[y_test == -1] = 0\n",
    "\n",
    "#converts -1 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = []\n",
    "        # Calculate mean and standard deviation for each class and feature\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.parameters.append([(np.mean(X_c[:, i]), np.std(X_c[:, i])) for i in range(X_c.shape[1])])\n",
    "        \n",
    "\n",
    "    #NormalPDF probability\n",
    "    def _calculate_probability(self, x, mean, stdev):\n",
    "        exponent = np.exp(-((x - mean) ** 2 / (2 * stdev ** 2)))\n",
    "        return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent\n",
    "\n",
    "    #Looping through dataset\n",
    "    def _calculate_class_probabilities(self, x):\n",
    "        probabilities = {}\n",
    "        for i, c in enumerate(self.classes):\n",
    "            probabilities[c] = 1\n",
    "            for j, param in enumerate(self.parameters[i]):\n",
    "                mean, stdev = param\n",
    "                probabilities[c] *= self._calculate_probability(x[j], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            probabilities = self._calculate_class_probabilities(x)\n",
    "            best_class = None\n",
    "            best_prob = -1\n",
    "            for c, prob in probabilities.items():\n",
    "                if best_class is None or prob > best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_class = c\n",
    "            predictions.append(best_class)\n",
    "        return predictions\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "def true_positives(y_true, y_pred, positive_label):\n",
    "    return np.sum((y_true == positive_label) & (y_pred == positive_label))\n",
    "\n",
    "def false_positives(y_true, y_pred, positive_label):\n",
    "    return np.sum((y_true != positive_label) & (y_pred == positive_label))\n",
    "\n",
    "def true_negatives(y_true, y_pred, negative_label):\n",
    "    return np.sum((y_true == negative_label) & (y_pred == negative_label))\n",
    "\n",
    "def false_negatives(y_true, y_pred, negative_label):\n",
    "    return np.sum((y_true != negative_label) & (y_pred != negative_label))\n",
    "\n",
    "def precision(y_true, y_pred, positive_label):\n",
    "    tp = true_positives(y_true, y_pred, positive_label)\n",
    "    fp = false_positives(y_true, y_pred, positive_label)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y_true, y_pred, positive_label):\n",
    "    tp = true_positives(y_true, y_pred, positive_label)\n",
    "    fn = false_negatives(y_true, y_pred, positive_label)\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=NaiveBayes()\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "   \n",
    "# making predictions on the testing set\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurancy: 0.98\n",
      "true pos: 16\n",
      "false pos: 1\n",
      "true neg: 33\n",
      "false neg: 16\n",
      "precision: 0.9411764705882353\n",
      "recall: 0.32653061224489793\n"
     ]
    }
   ],
   "source": [
    "print(f'accurancy: {accuracy(y_test, y_pred)}')\n",
    "print(f'true pos: {true_positives(y_test, y_pred, positive_label=1)}')  # positive class label is 1\n",
    "print(f'false pos: {false_positives(y_test, y_pred, positive_label=1)}')\n",
    "print(f'true neg: {true_negatives(y_test, y_pred, negative_label=-1)}')  # negative class label is -1\n",
    "print(f'false neg: {false_negatives(y_test, y_pred, negative_label=-1)}')\n",
    "print(f'precision: {precision(y_test, y_pred, positive_label=1)}')\n",
    "print(f'recall: {recall(y_test, y_pred, positive_label=1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
